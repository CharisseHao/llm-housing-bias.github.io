<div class="section-content">
    <link rel="stylesheet" href="static/css/common.css">

    <h2>Methods</h2>
    
    <h3>Models</h3>
    <p>
        We tested eight unique models across two prompts to uncover potential biases. For the first prompt, we selected models from Google’s gemma-2-2b-it, OpenAI’s gpt-3.5-Turbo-0125, gpt-4o-2024-08-06, and gpt-4o-Mini-2024-07-18, InceptionAI’s Jais-Family-1P3B-Chat, and Meta’s Meta-Llama-3-8B-Instruct based on their varying abilities to generate responses without rejections. After reviewing the initial results, we adjusted our selection for the second prompt, replacing InceptionAI’s model with two alternatives—Microsoft’s Phi-3-mini-4k-instruct and Meta’s Llama-3.2-3B-Instruct—while keeping the rest unchanged. Our choices prioritized open-source models with widespread recognition, as they are more likely candidates for adoption by landlords or other tenant evaluation software.
    </p>

    <h3>Interviews</h3>
    <p>
        To inform our prompt variables and structure, we attempted to interview relevant community members, including current renters and housing sector professionals. Interviews with student renters provided insight into application processes and housing concerns, revealing two common formats: informal email applications and formal applications forms. These typically included details such as name, living status, occupation, and credit score—though background checks were not mentioned despite their prevalence. Due to time constraints and low response rates, we were unable to interview housing professionals. However based on our research and limited email responses, LLM and AI-driven tenant screening appears to be a relatively unknown issue at the moment. 
    </p>

    <h3>Prompt Generation and Submission</h3>
    <p>
        For each set of prompts, the process began with prompt engineering, followed by the use of a bulk generator script to create thousands of variations. This script systematically varied input variables selected for their key role in housing decisions, enabling both singular and intersectional analyses to identify potential biases. LLMs were instructed to return a numerical score in the format “Score: X/100” without explanation, simplifying statistical testing and mimicking real-world tenant evaluation systems (Desai 2024). Prompts were submitted using <i>Batchwizard</i> for OpenAI models and Runpod for others, after which responses were downloaded, validated, and prepared for analysis.
    </p>

    <h3>Statistical Techniques</h3>
    <p> 
        Since the data did not meet parametric assumptions, as determined by the Shapiro-Wilk test for normality and Levene’s test for homogeneity of variance, we used non-parametric methods. Specifically, we applied the Kruskal-Wallis test to identify any significant differences across groups, followed by Dunn’s test with Bonferroni correction for multiple comparisons to perform pairwise analyses.
    </p>
    <!-- More significant differences and failed tests indicated a higher likelihood of bias. -->
</div>
